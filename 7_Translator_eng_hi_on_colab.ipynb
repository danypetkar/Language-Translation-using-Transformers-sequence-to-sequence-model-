{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f43079c-a022-4798-a9ab-74e7b38b342a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#!pip install datasets\\n#!pip install transformers\\n#!pip install sentencepiece\\n#!pip install transformers[torch]\\n#!pip install sacrebleu\\n#!pip install evaluate\\n#!pip install sacrebleu\\n#!pip install accelerate -U\\n#!pip install gradio \\n#!pip install kaleido cohere  openai tiktoken typing-extensions==4.5.0\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#!pip install datasets\n",
    "#!pip install transformers\n",
    "#!pip install sentencepiece\n",
    "#!pip install transformers[torch]\n",
    "#!pip install sacrebleu\n",
    "#!pip install evaluate\n",
    "#!pip install sacrebleu\n",
    "#!pip install accelerate -U\n",
    "#!pip install gradio \n",
    "#!pip install kaleido cohere  openai tiktoken typing-extensions==4.5.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7156039-e92f-4ab1-998d-3098bd4d23ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193adbcf-5376-418d-91dc-c986928370c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d46bd9-3946-4bec-b7c9-faf2431ba9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'एमएनएपी शिक्षकों के राष्ट्रपति, राजस्वीवर ने इस पुरस्कार को पेश करने के द्वारा स्कूल की प्रतिष्ठा की.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = dataset['validation'][2]['translation']['en']\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "     **inputs,  max_length=256\n",
    " )\n",
    "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7e0154-9e43-4bd8-8def-136cbb43cf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मनपा शिक्षक संघ के अध्यक्ष राजेश गवरे ने स्कूल को भेंट देकर सराहना की।'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][2]['translation']['hi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed28045-5976-4025-b45e-691a2dd8be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "  inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n",
    "  targets = [ex[\"hi\"] for ex in examples[\"translation\"]]\n",
    "\n",
    "  model_inputs = tokenizer(inputs, max_length=max_length, truncation=True)\n",
    "  labels = tokenizer(targets,max_length=max_length, truncation=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "  return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cfe18b-1c1e-42ac-b6e3-15ec27958ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets_validation = dataset['validation'].map(\n",
    "    preprocess_function,\n",
    "    batched= True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "tokenized_datasets_test = dataset['test'].map(\n",
    "    preprocess_function,\n",
    "    batched= True,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    batch_size = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "705c6d67-c5bc-4657-9cf3-1d7ce17d92f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e882b6-8ac5-4ce7-b99d-c676a2daec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the layers and freeze the specified number of layers\n",
    "# Specify the number of layers to freeze from the end\n",
    "\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = True\n",
    "num_layers_to_freeze = 10  # Adjust as needed\n",
    "for layer_index, layer in enumerate(model.model.encoder.layers):\n",
    "    print\n",
    "    if layer_index < len(model.model.encoder.layers) - num_layers_to_freeze:\n",
    "        for parameter in layer.parameters():\n",
    "            parameter.requires_grad = False\n",
    "\n",
    "num_layers_to_freeze = 10  # Adjust as needed\n",
    "for layer_index, layer in enumerate(model.model.decoder.layers):\n",
    "    print\n",
    "    if layer_index < len(model.model.encoder.layers) - num_layers_to_freeze:\n",
    "        for parameter in layer.parameters():\n",
    "            parameter.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0935662b-aeed-4424-829f-1b7f84802aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d458cbcc-2313-41bb-8bce-39a2c0be4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if a GPU is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "model.to(device)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    f\"finetuned-nlp-en-hi\",\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=2,\n",
    "    max_steps=2000,\n",
    "    fp16=True,\n",
    "    optim='adafactor',\n",
    "    per_device_eval_batch_size=16,\n",
    "    metric_for_best_model=\"eval_bleu\",\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "# This code is modified by Susobhan Akhuli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8960bf-9f1f-480e-9fca-88abdbb494ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/2000 00:23 < 3:15:50, 0.17 it/s, Epoch 0.06/26]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets_test,\n",
    "    eval_dataset=tokenized_datasets_validation,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe84b408-9147-4711-bae6-9dc7ca262a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GetCoreSchemaHandler' from 'pydantic' (C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\pydantic\\__init__.cp38-win_amd64.pyd)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate\u001b[39m(text):\n\u001b[0;32m      5\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_simple_templates\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessing_utils\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\_simple_templates\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpledropdown\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDropdown\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpleimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImage\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpletextbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleTextbox\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\_simple_templates\\simpledropdown.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Sequence\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component, FormComponent\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Events\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\components\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated_image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotatedImage\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Component,\n\u001b[0;32m      5\u001b[0m     FormComponent,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     get_component_instance,\n\u001b[0;32m     11\u001b[0m )\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\components\\annotated_image.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m handle_file\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m document\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processing_utils, utils\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\processing_utils.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m client_utils\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, ImageSequence, PngImagePlugin\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, wasm_utils\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel, GradioRootModel, JsonData\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Error\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\utils.py:58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blocks_context\n\u001b[1;32m---> 58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     59\u001b[0m     BlocksConfigDict,\n\u001b[0;32m     60\u001b[0m     DeveloperPath,\n\u001b[0;32m     61\u001b[0m     FileData,\n\u001b[0;32m     62\u001b[0m     UserProvidedPath,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Error, InvalidPathError\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m en\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfm\\lib\\site-packages\\gradio\\data_classes.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m document\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m traverse\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     BaseModel,\n\u001b[0;32m     28\u001b[0m     GetCoreSchemaHandler,\n\u001b[0;32m     29\u001b[0m     GetJsonSchemaHandler,\n\u001b[0;32m     30\u001b[0m     RootModel,\n\u001b[0;32m     31\u001b[0m     ValidationError,\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JsonSchemaValue\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_core\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core_schema\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'GetCoreSchemaHandler' from 'pydantic' (C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\pydantic\\__init__.cp38-win_amd64.pyd)"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def translate(text):\n",
    "  inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "  translated_tokens = model.generate(**inputs,  max_length=256)\n",
    "  results = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "  return results\n",
    "\n",
    "\n",
    "#Creating the User Interface Space\n",
    "interface = gr.Interface(fn=translate,inputs=gr.Textbox(lines=2, placeholder='Text to translate'),\n",
    "                        outputs='text')\n",
    "#launching the interface\n",
    "interface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d849ade0-7611-4e48-a883-22977617f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text  = \"how are you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "831a5af4-913f-4d06-9e43-3b8b75524f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "translated_tokens = model.generate(**inputs,  max_length=256)\n",
    "results = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "293eff3f-d58c-4c5b-bf85-31f7a4e87bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'यह हैं'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd8aee-74ce-479b-a133-bbb6b14cb580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
